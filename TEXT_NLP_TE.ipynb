{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import math\n",
    "\n",
    "import string, unicodedata\n",
    "#import contractions\n",
    "#import inflect\n",
    "\n",
    "#from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"http://www.dailymail.co.uk/sport/index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "links=[a['href'].split('#')[0] for a in soup.find_all('a',attrs={'href':re.compile(\"^http://www.dailymail.co.uk/sport\")})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sportsarticles=[]\n",
    "\n",
    "for link in links:\n",
    "    body=requests.get(link)\n",
    "    article=BeautifulSoup(body.content,'html.parser')\n",
    "    paras=article.find_all('p',class_=\"mol-para-with-font\")\n",
    "    if paras:\n",
    "        one=[]\n",
    "        for text in paras:\n",
    "            one.append(text.get_text())\n",
    "    sportsarticles.append(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing nested list, converting each article as a big string instead\n",
    "newlist=[]\n",
    "for a in sportsarticles:\n",
    "    b= ' '.join(a)\n",
    "    newlist.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicate articles\n",
    "final_list = []\n",
    "for num in newlist:\n",
    "    if num not in final_list:\n",
    "        final_list.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"articles7Aug.csv\", \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in final_list:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rajat13440\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rajat13440\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\rajat13440\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\rajat13440\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\rajat13440\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\rajat13440\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rajat13440\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rajat13440\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=pd.DataFrame({\"articles\":final_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"Tokens2\"]=articles[\"articles\"].apply(lambda x:nltk.word_tokenize(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"MsgSentenceTokens\"]=articles[\"articles\"].apply(lambda x:nltk.sent_tokenize(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in nltk.corpus.stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(x):\n",
    "    norm=[word.lower() for word in x]\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x1=remove_stopwords(x)\n",
    "    x2=remove_punctuation(x1)\n",
    "    x3=lower(x2)\n",
    "    #print(x3)\n",
    "    #x3=remove_non_ascii(x2)\n",
    "    return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>MsgSentenceTokens</th>\n",
       "      <th>NormTokens</th>\n",
       "      <th>POS_Msg</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>stems</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>Tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul Pogba's agent is trying to engineer a sen...</td>\n",
       "      <td>[Paul, Pogba, 's, agent, is, trying, to, engin...</td>\n",
       "      <td>[Paul Pogba's agent is trying to engineer a se...</td>\n",
       "      <td>[paul, pogba, s, agent, trying, engineer, sens...</td>\n",
       "      <td>[(paul, NN), (pogba, NN), (s, NN), (agent, NN)...</td>\n",
       "      <td>0</td>\n",
       "      <td>[paul, pogb, s, ag, try, engin, sens, deal, ma...</td>\n",
       "      <td>[paul, pogba, s, agent, try, engineer, sensati...</td>\n",
       "      <td>[Paul, Pogba, 's, agent, is, trying, to, engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stan Kroenke has made a cash offer to buy Arse...</td>\n",
       "      <td>[Stan, Kroenke, has, made, a, cash, offer, to,...</td>\n",
       "      <td>[Stan Kroenke has made a cash offer to buy Ars...</td>\n",
       "      <td>[stan, kroenke, made, cash, offer, buy, arsena...</td>\n",
       "      <td>[(stan, NN), (kroenke, NNS), (made, VBN), (cas...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[stan, kroenk, mad, cash, off, buy, ars, deal,...</td>\n",
       "      <td>[stan, kroenke, make, cash, offer, buy, arsena...</td>\n",
       "      <td>[Stan, Kroenke, has, made, a, cash, offer, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's approaching the realm of panic stations f...</td>\n",
       "      <td>[It, 's, approaching, the, realm, of, panic, s...</td>\n",
       "      <td>[It's approaching the realm of panic stations ...</td>\n",
       "      <td>[it, s, approaching, realm, panic, stations, e...</td>\n",
       "      <td>[(it, PRP), (s, VBD), (approaching, VBG), (rea...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[it, s, approach, realm, pan, stat, engl, club...</td>\n",
       "      <td>[it, s, approach, realm, panic, station, engli...</td>\n",
       "      <td>[It, 's, approaching, the, realm, of, panic, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chelsea are 'set to pay Jan Oblak's £89million...</td>\n",
       "      <td>[Chelsea, are, 'set, to, pay, Jan, Oblak, 's, ...</td>\n",
       "      <td>[Chelsea are 'set to pay Jan Oblak's £89millio...</td>\n",
       "      <td>[chelsea, set, pay, jan, oblak, s, 89million, ...</td>\n",
       "      <td>[(chelsea, NN), (set, VBN), (pay, NN), (jan, N...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[chelse, set, pay, jan, oblak, s, 89million, r...</td>\n",
       "      <td>[chelsea, set, pay, jan, oblak, s, 89million, ...</td>\n",
       "      <td>[Chelsea, are, 'set, to, pay, Jan, Oblak, 's, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manchester United are ready to 'enter the race...</td>\n",
       "      <td>[Manchester, United, are, ready, to, 'enter, t...</td>\n",
       "      <td>[Manchester United are ready to 'enter the rac...</td>\n",
       "      <td>[manchester, united, ready, enter, race, sign,...</td>\n",
       "      <td>[(manchester, NN), (united, VBD), (ready, JJ),...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[manchest, unit, ready, ent, rac, sign, ousm, ...</td>\n",
       "      <td>[manchester, unite, ready, enter, race, sign, ...</td>\n",
       "      <td>[Manchester, United, are, ready, to, 'enter, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles  \\\n",
       "0  Paul Pogba's agent is trying to engineer a sen...   \n",
       "1  Stan Kroenke has made a cash offer to buy Arse...   \n",
       "2  It's approaching the realm of panic stations f...   \n",
       "3  Chelsea are 'set to pay Jan Oblak's £89million...   \n",
       "4  Manchester United are ready to 'enter the race...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Paul, Pogba, 's, agent, is, trying, to, engin...   \n",
       "1  [Stan, Kroenke, has, made, a, cash, offer, to,...   \n",
       "2  [It, 's, approaching, the, realm, of, panic, s...   \n",
       "3  [Chelsea, are, 'set, to, pay, Jan, Oblak, 's, ...   \n",
       "4  [Manchester, United, are, ready, to, 'enter, t...   \n",
       "\n",
       "                                   MsgSentenceTokens  \\\n",
       "0  [Paul Pogba's agent is trying to engineer a se...   \n",
       "1  [Stan Kroenke has made a cash offer to buy Ars...   \n",
       "2  [It's approaching the realm of panic stations ...   \n",
       "3  [Chelsea are 'set to pay Jan Oblak's £89millio...   \n",
       "4  [Manchester United are ready to 'enter the rac...   \n",
       "\n",
       "                                          NormTokens  \\\n",
       "0  [paul, pogba, s, agent, trying, engineer, sens...   \n",
       "1  [stan, kroenke, made, cash, offer, buy, arsena...   \n",
       "2  [it, s, approaching, realm, panic, stations, e...   \n",
       "3  [chelsea, set, pay, jan, oblak, s, 89million, ...   \n",
       "4  [manchester, united, ready, enter, race, sign,...   \n",
       "\n",
       "                                             POS_Msg  Sentiments  \\\n",
       "0  [(paul, NN), (pogba, NN), (s, NN), (agent, NN)...           0   \n",
       "1  [(stan, NN), (kroenke, NNS), (made, VBN), (cas...          -1   \n",
       "2  [(it, PRP), (s, VBD), (approaching, VBG), (rea...          -1   \n",
       "3  [(chelsea, NN), (set, VBN), (pay, NN), (jan, N...          -1   \n",
       "4  [(manchester, NN), (united, VBD), (ready, JJ),...          -1   \n",
       "\n",
       "                                               stems  \\\n",
       "0  [paul, pogb, s, ag, try, engin, sens, deal, ma...   \n",
       "1  [stan, kroenk, mad, cash, off, buy, ars, deal,...   \n",
       "2  [it, s, approach, realm, pan, stat, engl, club...   \n",
       "3  [chelse, set, pay, jan, oblak, s, 89million, r...   \n",
       "4  [manchest, unit, ready, ent, rac, sign, ousm, ...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [paul, pogba, s, agent, try, engineer, sensati...   \n",
       "1  [stan, kroenke, make, cash, offer, buy, arsena...   \n",
       "2  [it, s, approach, realm, panic, station, engli...   \n",
       "3  [chelsea, set, pay, jan, oblak, s, 89million, ...   \n",
       "4  [manchester, unite, ready, enter, race, sign, ...   \n",
       "\n",
       "                                             Tokens2  \n",
       "0  [Paul, Pogba, 's, agent, is, trying, to, engin...  \n",
       "1  [Stan, Kroenke, has, made, a, cash, offer, to,...  \n",
       "2  [It, 's, approaching, the, realm, of, panic, s...  \n",
       "3  [Chelsea, are, 'set, to, pay, Jan, Oblak, 's, ...  \n",
       "4  [Manchester, United, are, ready, to, 'enter, t...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"NormText\"]=articles[\"articles\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"POS_Msg\"]=articles[\"NormTokens\"].apply(lambda x:nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles.drop(\"Tokens2\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles[\"POS_Msg_Uni\"]=articles[\"NormTokens\"].apply(lambda x:nltk.pos_tag(x,tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def noun_POS(x):\n",
    "    words=nltk.pos_tag(x,tagset='universal')\n",
    "    mw= [word[0] for word in words if word[1]=='NOUN' or word[1]=='VERB']\n",
    "    return mw'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles[\"POS_Msg_2\"]=articles[\"NormTokens\"].apply(lambda x:noun_POS(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkMsg(x):\n",
    "    entities=nltk.chunk.ne_chunk(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"Chunked\"] = articles[\"POS_Msg\"].apply(lambda x: chunkMsg(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles[\"Chunked\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles[\"POS_Msg\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.drop([\"POS_Msg_2\",\"NormTokensNew\",\"POS_Msg_Uni\",\"Chunked\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>MsgSentenceTokens</th>\n",
       "      <th>NormTokens</th>\n",
       "      <th>POS_Msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul Pogba's agent is trying to engineer a sen...</td>\n",
       "      <td>[Paul, Pogba, 's, agent, is, trying, to, engin...</td>\n",
       "      <td>[Paul Pogba's agent is trying to engineer a se...</td>\n",
       "      <td>[paul, pogba, s, agent, trying, engineer, sens...</td>\n",
       "      <td>[(paul, NN), (pogba, NN), (s, NN), (agent, NN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stan Kroenke has made a cash offer to buy Arse...</td>\n",
       "      <td>[Stan, Kroenke, has, made, a, cash, offer, to,...</td>\n",
       "      <td>[Stan Kroenke has made a cash offer to buy Ars...</td>\n",
       "      <td>[stan, kroenke, made, cash, offer, buy, arsena...</td>\n",
       "      <td>[(stan, NN), (kroenke, NNS), (made, VBN), (cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's approaching the realm of panic stations f...</td>\n",
       "      <td>[It, 's, approaching, the, realm, of, panic, s...</td>\n",
       "      <td>[It's approaching the realm of panic stations ...</td>\n",
       "      <td>[it, s, approaching, realm, panic, stations, e...</td>\n",
       "      <td>[(it, PRP), (s, VBD), (approaching, VBG), (rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chelsea are 'set to pay Jan Oblak's £89million...</td>\n",
       "      <td>[Chelsea, are, 'set, to, pay, Jan, Oblak, 's, ...</td>\n",
       "      <td>[Chelsea are 'set to pay Jan Oblak's £89millio...</td>\n",
       "      <td>[chelsea, set, pay, jan, oblak, s, 89million, ...</td>\n",
       "      <td>[(chelsea, NN), (set, VBN), (pay, NN), (jan, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manchester United are ready to 'enter the race...</td>\n",
       "      <td>[Manchester, United, are, ready, to, 'enter, t...</td>\n",
       "      <td>[Manchester United are ready to 'enter the rac...</td>\n",
       "      <td>[manchester, united, ready, enter, race, sign,...</td>\n",
       "      <td>[(manchester, NN), (united, VBD), (ready, JJ),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles  \\\n",
       "0  Paul Pogba's agent is trying to engineer a sen...   \n",
       "1  Stan Kroenke has made a cash offer to buy Arse...   \n",
       "2  It's approaching the realm of panic stations f...   \n",
       "3  Chelsea are 'set to pay Jan Oblak's £89million...   \n",
       "4  Manchester United are ready to 'enter the race...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Paul, Pogba, 's, agent, is, trying, to, engin...   \n",
       "1  [Stan, Kroenke, has, made, a, cash, offer, to,...   \n",
       "2  [It, 's, approaching, the, realm, of, panic, s...   \n",
       "3  [Chelsea, are, 'set, to, pay, Jan, Oblak, 's, ...   \n",
       "4  [Manchester, United, are, ready, to, 'enter, t...   \n",
       "\n",
       "                                   MsgSentenceTokens  \\\n",
       "0  [Paul Pogba's agent is trying to engineer a se...   \n",
       "1  [Stan Kroenke has made a cash offer to buy Ars...   \n",
       "2  [It's approaching the realm of panic stations ...   \n",
       "3  [Chelsea are 'set to pay Jan Oblak's £89millio...   \n",
       "4  [Manchester United are ready to 'enter the rac...   \n",
       "\n",
       "                                          NormTokens  \\\n",
       "0  [paul, pogba, s, agent, trying, engineer, sens...   \n",
       "1  [stan, kroenke, made, cash, offer, buy, arsena...   \n",
       "2  [it, s, approaching, realm, panic, stations, e...   \n",
       "3  [chelsea, set, pay, jan, oblak, s, 89million, ...   \n",
       "4  [manchester, united, ready, enter, race, sign,...   \n",
       "\n",
       "                                             POS_Msg  \n",
       "0  [(paul, NN), (pogba, NN), (s, NN), (agent, NN)...  \n",
       "1  [(stan, NN), (kroenke, NNS), (made, VBN), (cas...  \n",
       "2  [(it, PRP), (s, VBD), (approaching, VBG), (rea...  \n",
       "3  [(chelsea, NN), (set, VBN), (pay, NN), (jan, N...  \n",
       "4  [(manchester, NN), (united, VBD), (ready, JJ),...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=articles[\"POS_Msg\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cp.parse(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP no/DT wonder/NN)\n",
      "  (NP jose/NN)\n",
      "  (NP mourinho/NN)\n",
      "  is/VBZ\n",
      "  worried/VBN\n",
      "  about/IN\n",
      "  (NP the/DT start/NN)\n",
      "  of/IN\n",
      "  (NP the/DT new/JJ season/NN)\n",
      "  ./.\n",
      "  four/CD\n",
      "  days/NNS\n",
      "  to/TO\n",
      "  go/VB\n",
      "  until/IN\n",
      "  it/PRP\n",
      "  kicks/VBZ\n",
      "  off/RP\n",
      "  at/IN\n",
      "  (NP old/JJ trafford/NN)\n",
      "  and/CC\n",
      "  he/PRP\n",
      "  is/VBZ\n",
      "  still/RB\n",
      "  waiting/VBG\n",
      "  for/IN\n",
      "  (NP the/DT real/JJ manchester/NN)\n",
      "  united/VBD\n",
      "  to/TO\n",
      "  turn/VB\n",
      "  up/RP\n",
      "  ./.\n",
      "  this/DT\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  a/DT\n",
      "  strange/JJ\n",
      "  ,/,\n",
      "  disjointed/VBD\n",
      "  few/JJ\n",
      "  weeks/NNS\n",
      "  for/IN\n",
      "  (NP mourinho/NN)\n",
      "  and/CC\n",
      "  his/PRP$\n",
      "  players/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  it/PRP\n",
      "  showed/VBD\n",
      "  as/IN\n",
      "  they/PRP\n",
      "  completed/VBD\n",
      "  their/PRP$\n",
      "  (NP pre-season/NN)\n",
      "  on/IN\n",
      "  (NP a/DT muggy/JJ night/NN)\n",
      "  in/IN\n",
      "  (NP munich/NN)\n",
      "  ./.\n",
      "  on/IN\n",
      "  (NP this/DT evidence/NN)\n",
      "  ,/,\n",
      "  whatever/WDT\n",
      "  (NP team/NN)\n",
      "  united/VBD\n",
      "  put/VBD\n",
      "  out/RP\n",
      "  on/IN\n",
      "  (NP friday/JJ night/NN)\n",
      "  will/MD\n",
      "  struggle/VB\n",
      "  to/TO\n",
      "  overcome/VB\n",
      "  (NP leicester/NN)\n",
      "  never/RB\n",
      "  mind/VBP\n",
      "  challenge/JJ\n",
      "  manchester/NNP\n",
      "  (NP city/NN)\n",
      "  's/POS\n",
      "  (NP dominance/NN)\n",
      "  of/IN\n",
      "  (NP the/DT premier/NN)\n",
      "  (NP league/NN)\n",
      "  ./.\n",
      "  bayern/JJ\n",
      "  munich/JJ\n",
      "  (/(\n",
      "  3-4-3/JJ\n",
      "  )/)\n",
      "  :/:\n",
      "  (NP neuer/NN)\n",
      "  ;/:\n",
      "  kimmich/CC\n",
      "  (/(\n",
      "  rudy/VB\n",
      "  72/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  (NP sule/NN)\n",
      "  ,/,\n",
      "  hummels/NNS\n",
      "  (/(\n",
      "  boateng/IN\n",
      "  46/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  alaba/FW\n",
      "  (/(\n",
      "  bernat/IN\n",
      "  56/CD\n",
      "  )/)\n",
      "  ;/:\n",
      "  martinez/CC\n",
      "  ;/:\n",
      "  (NP robben/NN)\n",
      "  ,/,\n",
      "  (NP muller/NN)\n",
      "  ,/,\n",
      "  (NP thiago/NN)\n",
      "  (/(\n",
      "  rafinha/VB\n",
      "  60/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  (NP ribery/NN)\n",
      "  ;/:\n",
      "  (NP gnabry/NN)\n",
      "  ./.\n",
      "  subs/NNS\n",
      "  :/:\n",
      "  ulreich/JJ\n",
      "  ,/,\n",
      "  (NP hoffmann/NN)\n",
      "  ,/,\n",
      "  (NP lewandowski/NN)\n",
      "  ,/,\n",
      "  (NP boateng/NN)\n",
      "  ,/,\n",
      "  (NP goretzka/NN)\n",
      "  ,/,\n",
      "  (NP coman/NN)\n",
      "  ,/,\n",
      "  (NP mai/NN)\n",
      "  ,/,\n",
      "  (NP zylla/NN)\n",
      "  ,/,\n",
      "  (NP franzke/NN)\n",
      "  ./.\n",
      "  booked/VBN\n",
      "  :/:\n",
      "  (NP boateng/JJ scorer/NN)\n",
      "  :/:\n",
      "  (NP martinez/NN)\n",
      "  59/CD\n",
      "  (NP man/NN)\n",
      "  (NP utd/NN)\n",
      "  (/(\n",
      "  4-3-3/JJ\n",
      "  )/)\n",
      "  :/:\n",
      "  de/FW\n",
      "  gea/FW\n",
      "  (/(\n",
      "  grant/VB\n",
      "  78/CD\n",
      "  )/)\n",
      "  ;/:\n",
      "  darmian/JJ\n",
      "  (/(\n",
      "  jones/NNS\n",
      "  65/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  bailly/RB\n",
      "  (/(\n",
      "  smalling/VBG\n",
      "  51/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  lindelof/FW\n",
      "  (/(\n",
      "  tuanzebe/IN\n",
      "  78/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  shaw/FW\n",
      "  (/(\n",
      "  mitchell/VB\n",
      "  78/CD\n",
      "  )/)\n",
      "  ;/:\n",
      "  (NP herrera/NN)\n",
      "  (/(\n",
      "  garner/$\n",
      "  81/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  (NP pereira/NN)\n",
      "  ,/,\n",
      "  fred/VBN\n",
      "  (/(\n",
      "  chong/JJ\n",
      "  78/CD\n",
      "  )/)\n",
      "  ;/:\n",
      "  mata/NNS\n",
      "  (/(\n",
      "  mctominay/VB\n",
      "  65/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  (NP rashford/NN)\n",
      "  (/(\n",
      "  fosu-mensah/JJ\n",
      "  65/CD\n",
      "  )/)\n",
      "  ,/,\n",
      "  sanchez/UH\n",
      "  ./.\n",
      "  subs/NNS\n",
      "  :/:\n",
      "  (NP greenwood/NN)\n",
      "  ./.\n",
      "  (NP referee/NN)\n",
      "  :/:\n",
      "  (NP robert/NN)\n",
      "  (NP hartmann/NN)\n",
      "  after/IN\n",
      "  (NP city/NN)\n",
      "  gave/VBD\n",
      "  (NP another/DT demonstration/NN)\n",
      "  of/IN\n",
      "  what/WP\n",
      "  they/PRP\n",
      "  can/MD\n",
      "  do/VB\n",
      "  at/IN\n",
      "  (NP wembley/NN)\n",
      "  ,/,\n",
      "  united/JJ\n",
      "  looked/VBD\n",
      "  (NP every/DT bit/NN)\n",
      "  (NP a/DT team/NN)\n",
      "  that/WDT\n",
      "  is/VBZ\n",
      "  coming/VBG\n",
      "  together/RB\n",
      "  in/IN\n",
      "  drips/NNS\n",
      "  and/CC\n",
      "  (NP drabs/NN)\n",
      "  ./.\n",
      "  (NP marcus/NN)\n",
      "  (NP rashford/NN)\n",
      "  returned/VBD\n",
      "  for/IN\n",
      "  more/JJR\n",
      "  than/IN\n",
      "  (NP an/DT hour/NN)\n",
      "  here/RB\n",
      "  ,/,\n",
      "  officially/RB\n",
      "  inheriting/VBG\n",
      "  (NP the/DT no.10/JJ shirt/NN)\n",
      "  vacated/VBN\n",
      "  by/IN\n",
      "  (NP zlatan/NN)\n",
      "  (NP ibrahimovic/NN)\n",
      "  ,/,\n",
      "  while/IN\n",
      "  phil/JJ\n",
      "  jones/NNS\n",
      "  and/CC\n",
      "  (NP victor/NN)\n",
      "  (NP lindelof/NN)\n",
      "  also/RB\n",
      "  played/VBD\n",
      "  for/IN\n",
      "  (NP the/DT first/JJ time/NN)\n",
      "  since/IN\n",
      "  (NP the/DT world/NN)\n",
      "  (NP cup/NN)\n",
      "  ./.\n",
      "  but/CC\n",
      "  there/EX\n",
      "  was/VBD\n",
      "  still/RB\n",
      "  (NP no/DT paul/NN)\n",
      "  (NP pogba/NN)\n",
      "  ,/,\n",
      "  (NP no/DT romelu/NN)\n",
      "  (NP lukaku/NN)\n",
      "  ,/,\n",
      "  (NP no/DT jesse/NN)\n",
      "  lingard/RB\n",
      "  ,/,\n",
      "  (NP no/DT ashley/NN)\n",
      "  young/JJ\n",
      "  and/CC\n",
      "  (NP no/DT marouane/NN)\n",
      "  (NP fellaini/NN)\n",
      "  ./.\n",
      "  nemanja/CC\n",
      "  matic/JJ\n",
      "  and/CC\n",
      "  (NP antonio/JJ valencia/NN)\n",
      "  are/VBP\n",
      "  injured/VBN\n",
      "  ./.\n",
      "  anthony/JJ\n",
      "  martial/JJ\n",
      "  and/CC\n",
      "  (NP marcos/JJ rojo/NN)\n",
      "  were/VBD\n",
      "  left/VBN\n",
      "  at/IN\n",
      "  (NP home/NN)\n",
      "  when/WRB\n",
      "  united/JJ\n",
      "  flew/VBD\n",
      "  to/TO\n",
      "  germany/VB\n",
      "  ,/,\n",
      "  casting/VBG\n",
      "  (NP further/JJ doubt/NN)\n",
      "  over/IN\n",
      "  their/PRP$\n",
      "  futures/NNS\n",
      "  at/IN\n",
      "  (NP old/JJ trafford/NN)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  eric/JJ\n",
      "  bailly/RB\n",
      "  limped/VBD\n",
      "  off/RP\n",
      "  early/JJ\n",
      "  in/IN\n",
      "  (NP the/DT second/JJ half/NN)\n",
      "  ./.\n",
      "  (NP a/DT new/JJ centre-half/NN)\n",
      "  remains/VBZ\n",
      "  (NP the/DT priority/NN)\n",
      "  and/CC\n",
      "  (NP mourinho/NN)\n",
      "  is/VBZ\n",
      "  banking/VBG\n",
      "  on/IN\n",
      "  (NP united/JJ chief/JJ ed/NN)\n",
      "  (NP woodward/NN)\n",
      "  delivering/VBG\n",
      "  one/CD\n",
      "  ./.\n",
      "  united/VBN\n",
      "  were/VBD\n",
      "  reported/VBN\n",
      "  to/TO\n",
      "  have/VB\n",
      "  stepped/VBN\n",
      "  up/RP\n",
      "  their/PRP$\n",
      "  (NP interest/NN)\n",
      "  in/IN\n",
      "  (NP harry/NN)\n",
      "  (NP maguire/NN)\n",
      "  with/IN\n",
      "  (NP a/DT £75million/NN)\n",
      "  (NP bid/NN)\n",
      "  on/IN\n",
      "  (NP sunday/JJ night/NN)\n",
      "  as/IN\n",
      "  (NP leicester/NN)\n",
      "  continue/VBP\n",
      "  to/TO\n",
      "  resist/VB\n",
      "  ./.\n",
      "  it/PRP\n",
      "  's/VBZ\n",
      "  understood/JJ\n",
      "  that/IN\n",
      "  (NP jerome/JJ boateng/NN)\n",
      "  –/VBD\n",
      "  (NP a/DT half-time/JJ substitute/NN)\n",
      "  for/IN\n",
      "  (NP bayern/NN)\n",
      "  here/RB\n",
      "  –/NNP\n",
      "  is/VBZ\n",
      "  emerging/VBG\n",
      "  as/IN\n",
      "  (NP another/DT strong/JJ possibility/NN)\n",
      "  even/RB\n",
      "  though/IN\n",
      "  he/PRP\n",
      "  would/MD\n",
      "  cost/VB\n",
      "  £50m/NNP\n",
      "  and/CC\n",
      "  turns/VBZ\n",
      "  30/CD\n",
      "  (NP next/JJ month/NN)\n",
      "  ./.\n",
      "  asked/VBD\n",
      "  about/IN\n",
      "  (NP boateng/NN)\n",
      "  ,/,\n",
      "  (NP mourinho/NN)\n",
      "  said/VBD\n",
      "  :/:\n",
      "  'my/CD\n",
      "  (NP ceo/NN)\n",
      "  knows/VBZ\n",
      "  what/WP\n",
      "  (NP i/NN)\n",
      "  want/VBP\n",
      "  for/IN\n",
      "  quite/RB\n",
      "  (NP a/DT long/JJ time/NN)\n",
      "  ,/,\n",
      "  i/RB\n",
      "  know/VBP\n",
      "  he/PRP\n",
      "  tries/VBZ\n",
      "  to/TO\n",
      "  do/VB\n",
      "  the/DT\n",
      "  best/JJS\n",
      "  for/IN\n",
      "  me/PRP\n",
      "  and/CC\n",
      "  i/VB\n",
      "  still/RB\n",
      "  have/VBP\n",
      "  a/DT\n",
      "  few/JJ\n",
      "  days/NNS\n",
      "  to/TO\n",
      "  wait/VB\n",
      "  to/TO\n",
      "  see/VB\n",
      "  what/WP\n",
      "  happens/VBZ\n",
      "  ./.\n",
      "  '/''\n",
      "  otherwise/RB\n",
      "  ,/,\n",
      "  (NP the/DT united/JJ boss/NN)\n",
      "  is/VBZ\n",
      "  preparing/VBG\n",
      "  to/TO\n",
      "  make/VB\n",
      "  the/DT\n",
      "  most/JJS\n",
      "  out/IN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  players/NNS\n",
      "  he/PRP\n",
      "  has/VBZ\n",
      "  available/JJ\n",
      "  against/IN\n",
      "  (NP leicester/NN)\n",
      "  ./.\n",
      "  'we/CC\n",
      "  were/VBD\n",
      "  unlucky/JJ\n",
      "  to/TO\n",
      "  get/VB\n",
      "  (NP the/DT friday/JJ game/NN)\n",
      "  so/RB\n",
      "  monday/RB\n",
      "  ,/,\n",
      "  (NP tuesday/NN)\n",
      "  ,/,\n",
      "  (NP wednesday/NN)\n",
      "  ,/,\n",
      "  (NP thursday/NN)\n",
      "  is/VBZ\n",
      "  not/RB\n",
      "  enough/RB\n",
      "  ,/,\n",
      "  '/''\n",
      "  he/PRP\n",
      "  added/VBD\n",
      "  ./.\n",
      "  'we/NNS\n",
      "  have/VBP\n",
      "  to/TO\n",
      "  organise/VB\n",
      "  (NP the/DT week/NN)\n",
      "  in/IN\n",
      "  (NP a/DT way/NN)\n",
      "  that/IN\n",
      "  we/PRP\n",
      "  can/MD\n",
      "  arrive/VB\n",
      "  fresh/JJ\n",
      "  for/IN\n",
      "  (NP friday/NN)\n",
      "  because/IN\n",
      "  (NP friday/NN)\n",
      "  starts/VBZ\n",
      "  (NP the/DT premier/NN)\n",
      "  (NP league/NN)\n",
      "  and/CC\n",
      "  we/PRP\n",
      "  play/VBP\n",
      "  for/IN\n",
      "  points/NNS\n",
      "  and/CC\n",
      "  (NP friday/NN)\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  players/NNS\n",
      "  we/PRP\n",
      "  have/VBP\n",
      "  ./.\n",
      "  'there/EX\n",
      "  is/VBZ\n",
      "  (NP no/DT time/NN)\n",
      "  to/TO\n",
      "  cry/VB\n",
      "  for/IN\n",
      "  the/DT\n",
      "  players/NNS\n",
      "  that/WDT\n",
      "  are/VBP\n",
      "  not/RB\n",
      "  going/VBG\n",
      "  to/TO\n",
      "  be/VB\n",
      "  ./.\n",
      "  on/IN\n",
      "  (NP friday/NN)\n",
      "  we/PRP\n",
      "  go/VBP\n",
      "  with/IN\n",
      "  the/DT\n",
      "  best/JJS\n",
      "  (NP possible/JJ team/NN)\n",
      "  ./.\n",
      "  '/''\n",
      "  (NP united/JJ look/NN)\n",
      "  (NP anything/NN)\n",
      "  but/CC\n",
      "  (NP the/DT finished/JJ article/NN)\n",
      "  and/CC\n",
      "  it/PRP\n",
      "  's/VBZ\n",
      "  hard/JJ\n",
      "  to/TO\n",
      "  see/VB\n",
      "  how/WRB\n",
      "  they/PRP\n",
      "  can/MD\n",
      "  click/VB\n",
      "  into/IN\n",
      "  (NP gear/NN)\n",
      "  in/IN\n",
      "  four/CD\n",
      "  days/NNS\n",
      "  after/IN\n",
      "  such/JJ\n",
      "  (NP a/DT fragmented/JJ preparation/NN)\n",
      "  ./.\n",
      "  they/PRP\n",
      "  were/VBD\n",
      "  under/IN\n",
      "  (NP the/DT cosh/NN)\n",
      "  throughout/IN\n",
      "  here/RB\n",
      "  and/CC\n",
      "  david/VB\n",
      "  de/FW\n",
      "  gea/FW\n",
      "  made/VBD\n",
      "  first/JJ\n",
      "  half/JJ\n",
      "  saves/NNS\n",
      "  from/IN\n",
      "  (NP thiago/NN)\n",
      "  (NP alcantara/NN)\n",
      "  and/CC\n",
      "  (NP serge/NN)\n",
      "  (NP gnabry/NN)\n",
      "  ./.\n",
      "  however/RB\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  was/VBD\n",
      "  beaten/VBN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  59th/CD\n",
      "  (NP minute/NN)\n",
      "  when/WRB\n",
      "  (NP javi/NN)\n",
      "  (NP martinez/NN)\n",
      "  rose/VBD\n",
      "  to/TO\n",
      "  score/VB\n",
      "  with/IN\n",
      "  a/DT\n",
      "  glancing/VBG\n",
      "  (NP header/NN)\n",
      "  from/IN\n",
      "  (NP thiago/NN)\n",
      "  's/POS\n",
      "  (NP corner/NN)\n",
      "  ,/,\n",
      "  (NP a/DT timely/JJ reminder/NN)\n",
      "  perhaps/RB\n",
      "  of/IN\n",
      "  united/JJ\n",
      "  's/POS\n",
      "  (NP need/NN)\n",
      "  for/IN\n",
      "  (NP an/DT upgrade/NN)\n",
      "  in/IN\n",
      "  (NP central/JJ defence/NN)\n",
      "  ./.\n",
      "  (NP manuel/NN)\n",
      "  (NP neuer/NN)\n",
      "  did/VBD\n",
      "  not/RB\n",
      "  have/VB\n",
      "  (NP a/DT single/JJ save/NN)\n",
      "  to/TO\n",
      "  make/VB\n",
      "  and/CC\n",
      "  mourinho/VB\n",
      "  ended/VBD\n",
      "  (NP the/DT game/NN)\n",
      "  by/IN\n",
      "  sending/VBG\n",
      "  on/IN\n",
      "  the/DT\n",
      "  kids/NNS\n",
      "  and/CC\n",
      "  (NP third-choice/JJ keeper/NN)\n",
      "  (NP lee/NN)\n",
      "  (NP grant/NN)\n",
      "  ./.\n",
      "  maybe/RB\n",
      "  it/PRP\n",
      "  was/VBD\n",
      "  (NP a/DT message/NN)\n",
      "  to/TO\n",
      "  woodward/VB\n",
      "  ./.\n",
      "  their/PRP$\n",
      "  (NP strained/JJ relationship/NN)\n",
      "  could/MD\n",
      "  deteriorate/VB\n",
      "  even/RB\n",
      "  further/RB\n",
      "  if/IN\n",
      "  there/EX\n",
      "  is/VBZ\n",
      "  n't/RB\n",
      "  (NP a/DT new/JJ addition/NN)\n",
      "  through/IN\n",
      "  (NP the/DT door/NN)\n",
      "  by/IN\n",
      "  5pm/CD\n",
      "  on/IN\n",
      "  (NP thursday/NN)\n",
      "  ./.\n",
      "  (NP peter/NN)\n",
      "  (NP kenyon/NN)\n",
      "  ,/,\n",
      "  the/DT\n",
      "  former/JJ\n",
      "  united/JJ\n",
      "  and/CC\n",
      "  (NP chelsea/NN)\n",
      "  (NP chief/JJ executive/NN)\n",
      "  who/WP\n",
      "  played/VBD\n",
      "  (NP a/DT key/JJ role/NN)\n",
      "  in/IN\n",
      "  (NP mourinho/NN)\n",
      "  's/POS\n",
      "  (NP appointment/NN)\n",
      "  at/IN\n",
      "  (NP stamford/NN)\n",
      "  (NP bridge/NN)\n",
      "  in/IN\n",
      "  2004/CD\n",
      "  ,/,\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  there/EX\n",
      "  before/IN\n",
      "  and/CC\n",
      "  claimed/VBD\n",
      "  on/IN\n",
      "  (NP sunday/NN)\n",
      "  that/IN\n",
      "  (NP the/DT 55-year-old/JJ portuguese/JJ coach/NN)\n",
      "  can/MD\n",
      "  still/RB\n",
      "  make/VB\n",
      "  it/PRP\n",
      "  work/VB\n",
      "  ./.\n",
      "  but/CC\n",
      "  he/PRP\n",
      "  warned/VBD\n",
      "  :/:\n",
      "  'united/VBN\n",
      "  is/VBZ\n",
      "  bigger/JJR\n",
      "  than/IN\n",
      "  (NP anybody/NN)\n",
      "  ,/,\n",
      "  bigger/JJR\n",
      "  than/IN\n",
      "  any/DT\n",
      "  individual/JJ\n",
      "  and/CC\n",
      "  that/DT\n",
      "  's/VBZ\n",
      "  always/RB\n",
      "  been/VBN\n",
      "  (NP the/DT mantra/NN)\n",
      "  ./.\n",
      "  '/'')\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "pos_word_list=[]\n",
    "neg_word_list=[]\n",
    "neu_word_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSentiment(text):\n",
    "    temp=[]\n",
    "    ncount=0\n",
    "    pcount=0\n",
    "    for word in text:\n",
    "    \n",
    "        if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "            pcount+=1\n",
    "            if word not in pos_word_list:\n",
    "                pos_word_list.append(word)\n",
    "        elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "            ncount+=1\n",
    "            if word not in neg_word_list:\n",
    "                neg_word_list.append(word)\n",
    "        else:\n",
    "            if word not in neu_word_list: \n",
    "                neu_word_list.append(word)\n",
    "    if(pcount>0 and ncount==0):\n",
    "        temp.append(1)\n",
    "    elif(ncount%2>0):\n",
    "        temp.append(-1)\n",
    "    elif(ncount%2==0 and ncount==0):\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)            \n",
    "    sentiment=\"Pos: \"+ str(pcount) +\" Neg: \"+ str(ncount)\n",
    "    return temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"Sentiments\"]=articles[\"NormTokens\"].apply(lambda x:GetSentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>MsgSentenceTokens</th>\n",
       "      <th>NormTokens</th>\n",
       "      <th>POS_Msg</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul Pogba's agent is trying to engineer a sen...</td>\n",
       "      <td>[Paul, Pogba, 's, agent, is, trying, to, engin...</td>\n",
       "      <td>[Paul Pogba's agent is trying to engineer a se...</td>\n",
       "      <td>[paul, pogba, s, agent, trying, engineer, sens...</td>\n",
       "      <td>[(paul, NN), (pogba, NN), (s, NN), (agent, NN)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stan Kroenke has made a cash offer to buy Arse...</td>\n",
       "      <td>[Stan, Kroenke, has, made, a, cash, offer, to,...</td>\n",
       "      <td>[Stan Kroenke has made a cash offer to buy Ars...</td>\n",
       "      <td>[stan, kroenke, made, cash, offer, buy, arsena...</td>\n",
       "      <td>[(stan, NN), (kroenke, NNS), (made, VBN), (cas...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's approaching the realm of panic stations f...</td>\n",
       "      <td>[It, 's, approaching, the, realm, of, panic, s...</td>\n",
       "      <td>[It's approaching the realm of panic stations ...</td>\n",
       "      <td>[it, s, approaching, realm, panic, stations, e...</td>\n",
       "      <td>[(it, PRP), (s, VBD), (approaching, VBG), (rea...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chelsea are 'set to pay Jan Oblak's £89million...</td>\n",
       "      <td>[Chelsea, are, 'set, to, pay, Jan, Oblak, 's, ...</td>\n",
       "      <td>[Chelsea are 'set to pay Jan Oblak's £89millio...</td>\n",
       "      <td>[chelsea, set, pay, jan, oblak, s, 89million, ...</td>\n",
       "      <td>[(chelsea, NN), (set, VBN), (pay, NN), (jan, N...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manchester United are ready to 'enter the race...</td>\n",
       "      <td>[Manchester, United, are, ready, to, 'enter, t...</td>\n",
       "      <td>[Manchester United are ready to 'enter the rac...</td>\n",
       "      <td>[manchester, united, ready, enter, race, sign,...</td>\n",
       "      <td>[(manchester, NN), (united, VBD), (ready, JJ),...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tottenham are set to let Victor Wanyama leave ...</td>\n",
       "      <td>[Tottenham, are, set, to, let, Victor, Wanyama...</td>\n",
       "      <td>[Tottenham are set to let Victor Wanyama leave...</td>\n",
       "      <td>[tottenham, set, let, victor, wanyama, leave, ...</td>\n",
       "      <td>[(tottenham, NN), (set, VBN), (let, NN), (vict...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When Harry Kane dropped in on Mauricio Pochett...</td>\n",
       "      <td>[When, Harry, Kane, dropped, in, on, Mauricio,...</td>\n",
       "      <td>[When Harry Kane dropped in on Mauricio Pochet...</td>\n",
       "      <td>[when, harry, kane, dropped, mauricio, pochett...</td>\n",
       "      <td>[(when, WRB), (harry, NN), (kane, NN), (droppe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rio Ferdinand has warned Manchester United not...</td>\n",
       "      <td>[Rio, Ferdinand, has, warned, Manchester, Unit...</td>\n",
       "      <td>[Rio Ferdinand has warned Manchester United no...</td>\n",
       "      <td>[rio, ferdinand, warned, manchester, united, s...</td>\n",
       "      <td>[(rio, NN), (ferdinand, NN), (warned, VBD), (m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I’ve been impressed so far with almost everyth...</td>\n",
       "      <td>[I, ’, ve, been, impressed, so, far, with, alm...</td>\n",
       "      <td>[I’ve been impressed so far with almost everyt...</td>\n",
       "      <td>[i, impressed, far, almost, everything, ed, sm...</td>\n",
       "      <td>[(i, NN), (impressed, VBD), (far, RB), (almost...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Football was coming home three weeks ago. Or s...</td>\n",
       "      <td>[Football, was, coming, home, three, weeks, ag...</td>\n",
       "      <td>[Football was coming home three weeks ago., Or...</td>\n",
       "      <td>[football, coming, home, three, weeks, ago, or...</td>\n",
       "      <td>[(football, NN), (coming, VBG), (home, RB), (t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Joe Hart will complete his move from Mancheste...</td>\n",
       "      <td>[Joe, Hart, will, complete, his, move, from, M...</td>\n",
       "      <td>[Joe Hart will complete his move from Manchest...</td>\n",
       "      <td>[joe, hart, complete, move, manchester, city, ...</td>\n",
       "      <td>[(joe, JJ), (hart, NN), (complete, JJ), (move,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manchester United have 'tabled a final bid of ...</td>\n",
       "      <td>[Manchester, United, have, 'tabled, a, final, ...</td>\n",
       "      <td>[Manchester United have 'tabled a final bid of...</td>\n",
       "      <td>[manchester, united, tabled, final, bid, 40mil...</td>\n",
       "      <td>[(manchester, NN), (united, VBD), (tabled, JJ)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Everton have signed exciting Brazilian forward...</td>\n",
       "      <td>[Everton, have, signed, exciting, Brazilian, f...</td>\n",
       "      <td>[Everton have signed exciting Brazilian forwar...</td>\n",
       "      <td>[everton, signed, exciting, brazilian, forward...</td>\n",
       "      <td>[(everton, NN), (signed, VBD), (exciting, VBG)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jose Mourinho's complaints over Manchester Uni...</td>\n",
       "      <td>[Jose, Mourinho, 's, complaints, over, Manches...</td>\n",
       "      <td>[Jose Mourinho's complaints over Manchester Un...</td>\n",
       "      <td>[jose, mourinho, s, complaints, manchester, un...</td>\n",
       "      <td>[(jose, JJ), (mourinho, NN), (s, NN), (complai...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mike Ashley says he is being treated as a ‘pan...</td>\n",
       "      <td>[Mike, Ashley, says, he, is, being, treated, a...</td>\n",
       "      <td>[Mike Ashley says he is being treated as a ‘pa...</td>\n",
       "      <td>[mike, ashley, says, treated, pantomime, villa...</td>\n",
       "      <td>[(mike, NN), (ashley, NN), (says, VBZ), (treat...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Thibaut Courtois has failed to report for trai...</td>\n",
       "      <td>[Thibaut, Courtois, has, failed, to, report, f...</td>\n",
       "      <td>[Thibaut Courtois has failed to report for tra...</td>\n",
       "      <td>[thibaut, courtois, failed, report, training, ...</td>\n",
       "      <td>[(thibaut, JJ), (courtois, NN), (failed, VBD),...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Willian has attempted to explain what happened...</td>\n",
       "      <td>[Willian, has, attempted, to, explain, what, h...</td>\n",
       "      <td>[Willian has attempted to explain what happene...</td>\n",
       "      <td>[willian, attempted, explain, happened, contro...</td>\n",
       "      <td>[(willian, JJ), (attempted, VBD), (explain, NN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Despite his future at Manchester United lookin...</td>\n",
       "      <td>[Despite, his, future, at, Manchester, United,...</td>\n",
       "      <td>[Despite his future at Manchester United looki...</td>\n",
       "      <td>[despite, future, manchester, united, looking,...</td>\n",
       "      <td>[(despite, IN), (future, JJ), (manchester, NN)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maurizio Sarri has been airing his concerns in...</td>\n",
       "      <td>[Maurizio, Sarri, has, been, airing, his, conc...</td>\n",
       "      <td>[Maurizio Sarri has been airing his concerns i...</td>\n",
       "      <td>[maurizio, sarri, airing, concerns, private, m...</td>\n",
       "      <td>[(maurizio, NN), (sarri, NN), (airing, VBG), (...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chelsea's Willian has spoken of his desire to ...</td>\n",
       "      <td>[Chelsea, 's, Willian, has, spoken, of, his, d...</td>\n",
       "      <td>[Chelsea's Willian has spoken of his desire to...</td>\n",
       "      <td>[chelsea, s, willian, spoken, desire, one, day...</td>\n",
       "      <td>[(chelsea, NN), (s, NN), (willian, JJ), (spoke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             articles  \\\n",
       "0   Paul Pogba's agent is trying to engineer a sen...   \n",
       "1   Stan Kroenke has made a cash offer to buy Arse...   \n",
       "2   It's approaching the realm of panic stations f...   \n",
       "3   Chelsea are 'set to pay Jan Oblak's £89million...   \n",
       "4   Manchester United are ready to 'enter the race...   \n",
       "5   Tottenham are set to let Victor Wanyama leave ...   \n",
       "6   When Harry Kane dropped in on Mauricio Pochett...   \n",
       "7   Rio Ferdinand has warned Manchester United not...   \n",
       "8   I’ve been impressed so far with almost everyth...   \n",
       "9   Football was coming home three weeks ago. Or s...   \n",
       "10  Joe Hart will complete his move from Mancheste...   \n",
       "11  Manchester United have 'tabled a final bid of ...   \n",
       "12  Everton have signed exciting Brazilian forward...   \n",
       "13  Jose Mourinho's complaints over Manchester Uni...   \n",
       "14  Mike Ashley says he is being treated as a ‘pan...   \n",
       "15  Thibaut Courtois has failed to report for trai...   \n",
       "16  Willian has attempted to explain what happened...   \n",
       "17  Despite his future at Manchester United lookin...   \n",
       "18  Maurizio Sarri has been airing his concerns in...   \n",
       "19  Chelsea's Willian has spoken of his desire to ...   \n",
       "\n",
       "                                               Tokens  \\\n",
       "0   [Paul, Pogba, 's, agent, is, trying, to, engin...   \n",
       "1   [Stan, Kroenke, has, made, a, cash, offer, to,...   \n",
       "2   [It, 's, approaching, the, realm, of, panic, s...   \n",
       "3   [Chelsea, are, 'set, to, pay, Jan, Oblak, 's, ...   \n",
       "4   [Manchester, United, are, ready, to, 'enter, t...   \n",
       "5   [Tottenham, are, set, to, let, Victor, Wanyama...   \n",
       "6   [When, Harry, Kane, dropped, in, on, Mauricio,...   \n",
       "7   [Rio, Ferdinand, has, warned, Manchester, Unit...   \n",
       "8   [I, ’, ve, been, impressed, so, far, with, alm...   \n",
       "9   [Football, was, coming, home, three, weeks, ag...   \n",
       "10  [Joe, Hart, will, complete, his, move, from, M...   \n",
       "11  [Manchester, United, have, 'tabled, a, final, ...   \n",
       "12  [Everton, have, signed, exciting, Brazilian, f...   \n",
       "13  [Jose, Mourinho, 's, complaints, over, Manches...   \n",
       "14  [Mike, Ashley, says, he, is, being, treated, a...   \n",
       "15  [Thibaut, Courtois, has, failed, to, report, f...   \n",
       "16  [Willian, has, attempted, to, explain, what, h...   \n",
       "17  [Despite, his, future, at, Manchester, United,...   \n",
       "18  [Maurizio, Sarri, has, been, airing, his, conc...   \n",
       "19  [Chelsea, 's, Willian, has, spoken, of, his, d...   \n",
       "\n",
       "                                    MsgSentenceTokens  \\\n",
       "0   [Paul Pogba's agent is trying to engineer a se...   \n",
       "1   [Stan Kroenke has made a cash offer to buy Ars...   \n",
       "2   [It's approaching the realm of panic stations ...   \n",
       "3   [Chelsea are 'set to pay Jan Oblak's £89millio...   \n",
       "4   [Manchester United are ready to 'enter the rac...   \n",
       "5   [Tottenham are set to let Victor Wanyama leave...   \n",
       "6   [When Harry Kane dropped in on Mauricio Pochet...   \n",
       "7   [Rio Ferdinand has warned Manchester United no...   \n",
       "8   [I’ve been impressed so far with almost everyt...   \n",
       "9   [Football was coming home three weeks ago., Or...   \n",
       "10  [Joe Hart will complete his move from Manchest...   \n",
       "11  [Manchester United have 'tabled a final bid of...   \n",
       "12  [Everton have signed exciting Brazilian forwar...   \n",
       "13  [Jose Mourinho's complaints over Manchester Un...   \n",
       "14  [Mike Ashley says he is being treated as a ‘pa...   \n",
       "15  [Thibaut Courtois has failed to report for tra...   \n",
       "16  [Willian has attempted to explain what happene...   \n",
       "17  [Despite his future at Manchester United looki...   \n",
       "18  [Maurizio Sarri has been airing his concerns i...   \n",
       "19  [Chelsea's Willian has spoken of his desire to...   \n",
       "\n",
       "                                           NormTokens  \\\n",
       "0   [paul, pogba, s, agent, trying, engineer, sens...   \n",
       "1   [stan, kroenke, made, cash, offer, buy, arsena...   \n",
       "2   [it, s, approaching, realm, panic, stations, e...   \n",
       "3   [chelsea, set, pay, jan, oblak, s, 89million, ...   \n",
       "4   [manchester, united, ready, enter, race, sign,...   \n",
       "5   [tottenham, set, let, victor, wanyama, leave, ...   \n",
       "6   [when, harry, kane, dropped, mauricio, pochett...   \n",
       "7   [rio, ferdinand, warned, manchester, united, s...   \n",
       "8   [i, impressed, far, almost, everything, ed, sm...   \n",
       "9   [football, coming, home, three, weeks, ago, or...   \n",
       "10  [joe, hart, complete, move, manchester, city, ...   \n",
       "11  [manchester, united, tabled, final, bid, 40mil...   \n",
       "12  [everton, signed, exciting, brazilian, forward...   \n",
       "13  [jose, mourinho, s, complaints, manchester, un...   \n",
       "14  [mike, ashley, says, treated, pantomime, villa...   \n",
       "15  [thibaut, courtois, failed, report, training, ...   \n",
       "16  [willian, attempted, explain, happened, contro...   \n",
       "17  [despite, future, manchester, united, looking,...   \n",
       "18  [maurizio, sarri, airing, concerns, private, m...   \n",
       "19  [chelsea, s, willian, spoken, desire, one, day...   \n",
       "\n",
       "                                              POS_Msg  Sentiments  \n",
       "0   [(paul, NN), (pogba, NN), (s, NN), (agent, NN)...           0  \n",
       "1   [(stan, NN), (kroenke, NNS), (made, VBN), (cas...          -1  \n",
       "2   [(it, PRP), (s, VBD), (approaching, VBG), (rea...          -1  \n",
       "3   [(chelsea, NN), (set, VBN), (pay, NN), (jan, N...          -1  \n",
       "4   [(manchester, NN), (united, VBD), (ready, JJ),...          -1  \n",
       "5   [(tottenham, NN), (set, VBN), (let, NN), (vict...          -1  \n",
       "6   [(when, WRB), (harry, NN), (kane, NN), (droppe...           0  \n",
       "7   [(rio, NN), (ferdinand, NN), (warned, VBD), (m...           1  \n",
       "8   [(i, NN), (impressed, VBD), (far, RB), (almost...           1  \n",
       "9   [(football, NN), (coming, VBG), (home, RB), (t...           0  \n",
       "10  [(joe, JJ), (hart, NN), (complete, JJ), (move,...           0  \n",
       "11  [(manchester, NN), (united, VBD), (tabled, JJ)...           1  \n",
       "12  [(everton, NN), (signed, VBD), (exciting, VBG)...           1  \n",
       "13  [(jose, JJ), (mourinho, NN), (s, NN), (complai...          -1  \n",
       "14  [(mike, NN), (ashley, NN), (says, VBZ), (treat...          -1  \n",
       "15  [(thibaut, JJ), (courtois, NN), (failed, VBD),...           0  \n",
       "16  [(willian, JJ), (attempted, VBD), (explain, NN...           0  \n",
       "17  [(despite, IN), (future, JJ), (manchester, NN)...           0  \n",
       "18  [(maurizio, NN), (sarri, NN), (airing, VBG), (...          -1  \n",
       "19  [(chelsea, NN), (s, NN), (willian, JJ), (spoke...           1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems, lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['stems'] = articles[\"NormTokens\"].apply(lambda x: stem_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['lemmas'] = articles[\"NormTokens\"].apply(lambda x: lemmatize_verbs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.to_csv(\"processedData7Aug.csv\",sep=',',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
